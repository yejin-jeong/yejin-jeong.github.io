<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yejin Jeong</title>

    <meta name="author" content="Yejin Jeong">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yejin "Jeannie" Jeong
                </p>
                <p>
		Hello!ðŸ‘‹ I'm a researcher at the <a href="https://med.stanford.edu/healthcare-ai.html">Stanford Healthcare AI Applied Research Team (HEA3RT)</a>, where I support the implementation and evaluation of AI technologies in clinical settings.
		I'm completing an M.S. in <a href="https://med.stanford.edu/content/sm/master-clinical-informatics-management.html/">Clinical Informatics Management</a> at Stanford Medicine, and hold a B.A. in Psychology and Cognitive Science from Vanderbilt University.
		I'm passionate about bridging healthcare, AI, and human-centered learning and design, with recent interests in the research and education of prompt engineering.
                </p>
                <p style="text-align:center">
                  <a href="mailto:yejeong@stanford.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=8ke08fYAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/jeannie-yejin-jeong/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/yejinjeong.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/yejinjeong.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


   <tr>
  <td style="padding:16px;width:20%;vertical-align:middle">
    <img src="images/interview.png" alt="Ambient AI Scribes article" width="160" style="border-radius:6px;">
  </td>

  <td style="padding:8px;width:80%;vertical-align:middle">
    <span class="papertitle"><a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2831866">Physician Perspectives on Ambient AI Scribes </a></span>
    <br>
    Shreya J Shah, Trevor Crowell, <strong>Yejin Jeong</strong>, Anna Devon-Sand, Margaret Smith, Betsy Yang, Stephen P Ma, 
    April S Liang, Clarissa Delahaie, Caroline Hsia, Tait Shanafelt, Michael A Pfeffer, Christopher Sharp, 
    Steven Lin, Patricia Garcia
    <br>
    <em>JAMA Network Open</em>, 2025
    <p></p>
    <p>
	Interviews with 22 physicians highlighted how ambient AI scribes may improve workload, workâ€“life integration, 
	and patient engagement, while revealing barriers and opportunities for adoption.
    </p>
  </td>
</tr>
			  

 <tr>
  <td style="padding:16px;width:20%;vertical-align:middle">
    <img src="images/survey.png" alt="Ambient AI Scribes article" width="160" style="border-radius:6px;">
  </td>

  <td style="padding:8px;width:80%;vertical-align:middle">
    <span class="papertitle"><a href="https://academic.oup.com/jamia/article/32/2/375/7917501">Ambient artificial intelligence scribes: physician burnout and perspectives on usability and documentation burden </a></span>
    <br>
    Shreya J Shah, Anna Devon-Sand, Stephen P Ma, <strong>Yejin Jeong</strong>, Trevor Crowell, Margaret Smith, April S Liang, Clarissa Delahaie, 
	  Caroline Hsia, Tait Shanafelt, Michael A Pfeffer, Christopher Sharp, Steven Lin, Patricia Garcia
    <br>
    <em>JAMIA (Journal of the American Medical Informatics Association)</em>, 2025
    <p></p>
    <p>
     In a 3-month pilot with 48 physicians, an ambient AI scribe (DAX Copilot) was associated with 
		reduced task load and burnout, and improved usability and documentation efficiency.
    </p>
  </td>
</tr>

			    <tr>
  <td style="padding:16px;width:20%;vertical-align:middle">
    <img src="images/quant.png" alt="Ambient AI Scribes article" width="160" style="border-radius:6px;">
  </td>

  <td style="padding:8px;width:80%;vertical-align:middle">
    <span class="papertitle"><a href="https://academic.oup.com/jamia/article/32/2/381/7926614?login=true">Ambient artificial intelligence scribes: utilization and impact on documentation time </a></span>
    <br>
    Stephen P Ma, April S Liang, Shreya J Shah, Margaret Smith, <strong>Yejin Jeong</strong>, Anna Devon-Sand, 
	Trevor Crowell, Clarissa Delahaie, Caroline Hsia, Steven Lin, Tait Shanafelt, Michael A Pfeffer, Christopher Sharp, Patricia Garcia  
    <br>
    <em>JAMIA (Journal of the American Medical Informatics Association)</em>, 2025
    <p></p>
    <p>
     Used in 55% of 17,428 encounters across 45 physicians, an ambient AI scribe was associated with reduced documentation and EHR time, 
		suggesting potential to lessen documentation burden.
    </p>
  </td>
</tr>
			  

    <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
          <source src="images/r2r.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/r2r.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function r2r_start() {
            document.getElementById('r2r_image').style.opacity = "1";
          }

          function r2r_stop() {
            document.getElementById('r2r_image').style.opacity = "0";
          }
          r2r_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://relight-to-reconstruct.github.io/">
          <span class="papertitle">Generative Multiview Relighting for
3D Reconstruction under Extreme Illumination Variation</span>
        </a>
        <br>
        <a href="https://hadizayer.github.io/">Hadi Alzayer</a>,
        <a href="https://henzler.github.io/">Philipp Henzler</a>,
				<strong>Jonathan T. Barron</strong>, 
        <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>,
        <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>, 
        <a href="https://dorverbin.github.io/">Dor Verbin</a>
        <br>
        <em>CVPR</em>, 2025 &nbsp <font color=#FF8080><strong>(Highlight)</strong></font>
        <br>
        <a href="https://relight-to-reconstruct.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2412.15211">arXiv</a>
        <p></p>
        <p>
				Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
        </p>
      </td>
    </tr>


    <tr onmouseout="simvs_stop()" onmouseover="simvs_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='simvs_image'><video  width=100% muted autoplay loop>
          <source src="images/simvs.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/simvs.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function simvs_start() {
            document.getElementById('simvs_image').style.opacity = "1";
          }

          function simvs_stop() {
            document.getElementById('simvs_image').style.opacity = "0";
          }
          simvs_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://alextrevithick.github.io/simvs/">
          <span class="papertitle">SimVS: Simulating World Inconsistencies for Robust View Synthesis</span>
        </a>
        <br>
        <a href="https://alextrevithick.github.io/">Alex Trevithick</a>,
        <a href="https://scholar.google.com/citations?user=-KSDNZQAAAAJ&hl=en">Roni Paiss</a>,
        <a href="https://henzler.github.io/">Philipp Henzler</a>,
        <a href="https://dorverbin.github.io/">Dor Verbin</a>,
        <a href="https://www.cs.columbia.edu/~rundi/">Rundi Wu</a>,
        <a href="https://hadizayer.github.io/">Hadi Alzayer</a>,
        <a href="https://ruiqigao.github.io/">Ruiqi Gao</a>,
        <a  href="https://poolio.github.io/">Ben Poole</a>,
				<strong>Jonathan T. Barron</strong>, 
        <a href="https://holynski.org/">Aleksander Holynski</a>,
        <a href="https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
        <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>
        <br>
        <em>CVPR</em>, 2025
        <br>
        <a href="https://alextrevithick.github.io/simvs/">project page</a>
        /
        <a href="https://arxiv.org/abs/2412.07696">arXiv</a>
        <p></p>
        <p>
        Simulating the world with video models lets you make inconsistent captures consistent.
        </p>
      </td>
    </tr>


    <tr onmouseout="power_stop()" onmouseover="power_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='power_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/power.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/power.png' width="160">
        </div>
        <script type="text/javascript">
          function power_start() {
            document.getElementById('power_image').style.opacity = "1";
          }

          function power_stop() {
            document.getElementById('power_image').style.opacity = "0";
          }
          power_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://x.com/jon_barron/status/1891918200931061996">
			<span class="papertitle">A Power Transform
</span>
        </a>
        <br>
				<strong>Jonathan T. Barron</strong>
        <br>
        <em>arXiv</em>, 2025
        <br>
        <a href="https://x.com/jon_barron/status/1891918200931061996">tweet</a>
        /
        <a href="https://arxiv.org/abs/2502.10647">arXiv</a>
        <p></p>
        <p>
				A slight tweak to the Box-Cox power transform generalizes a variety of curves, losses, kernel functions, probability distributions, bump functions, and neural network activation functions.
        </p>
      </td>
    </tr>


    <tr onmouseout="cat3d_stop()" onmouseover="cat3d_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat3d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat3d_start() {
            document.getElementById('cat3d_image').style.opacity = "1";
          }

          function cat3d_stop() {
            document.getElementById('cat3d_image').style.opacity = "0";
          }
          cat3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://cat3d.github.io/">
			<span class="papertitle">CAT3D: Create Anything in 3D with Multi-View Diffusion Models
</span>
        </a>
        <br>
				<a href="https://ruiqigao.github.io/">Ruiqi Gao</a>*,
        <a href="https://holynski.org/">Aleksander Holynski</a>*, 
        <a href="https://henzler.github.io/">Philipp Henzler</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>, 
				<a href="http://ricardomartinbrualla.com/">Ricardo Martin Brualla</a>, 
        <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>,
				<strong>Jonathan T. Barron</strong>,
        <a href="https://poolio.github.io/">Ben Poole</a>*

        <br>
        <em>NeurIPS</em>, 2024 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://cat3d.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2405.10314">arXiv</a>
        <p></p>
        <p>
				A single model built around diffusion and NeRF that does text-to-3D, image-to-3D, and few-view reconstruction, trains in 1 minute, and renders at 60FPS in a browser.
        </p>
      </td>
    </tr>


			   </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Selected Presentations</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

  <tr>
  <td style="padding:16px;width:20%;vertical-align:middle">
    <img src="images/oral.png" width="160" style="border-radius:6px;">
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <span class="papertitle"> Evaluating Ambient AI Scribes through Quantitative and Qualitative Approaches </span>
    <br>
    Yejin Jeong (oral presentation)
    <br>
    <em>2025 STFM Annual Spring Conference. Presented May 2025
    <p></p>
  </td>
</tr>

 </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Teaching</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

			     <tr>
  <td style="padding:16px;width:20%;vertical-align:middle">
    <img src="images/interview.png" alt="Ambient AI Scribes article" width="160" style="border-radius:6px;">
  </td>

  <td style="padding:8px;width:80%;vertical-align:middle">
    <span class="papertitle"><a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2831866">Physician Perspectives on Ambient AI Scribes </a></span>
    <br>
    Shreya J Shah, Trevor Crowell, <strong>Yejin Jeong</strong>, Anna Devon-Sand, Margaret Smith, Betsy Yang, Stephen P Ma, 
    April S Liang, Clarissa Delahaie, Caroline Hsia, Tait Shanafelt, Michael A Pfeffer, Christopher Sharp, 
    Steven Lin, Patricia Garcia
    <br>
    <em>JAMA Network Open</em>, 2025
    <p></p>
    <p>
	Interviews with 22 physicians highlighted how ambient AI scribes may improve workload, workâ€“life integration, 
	and patient engagement, while revealing barriers and opportunities for adoption.
    </p>
  </td>
</tr>
			     <tr>
  <td style="padding:16px;width:20%;vertical-align:middle">
    <img src="images/interview.png" alt="Ambient AI Scribes article" width="160" style="border-radius:6px;">
  </td>

  <td style="padding:8px;width:80%;vertical-align:middle">
    <span class="papertitle"><a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2831866">Physician Perspectives on Ambient AI Scribes </a></span>
    <br>
    Shreya J Shah, Trevor Crowell, <strong>Yejin Jeong</strong>, Anna Devon-Sand, Margaret Smith, Betsy Yang, Stephen P Ma, 
    April S Liang, Clarissa Delahaie, Caroline Hsia, Tait Shanafelt, Michael A Pfeffer, Christopher Sharp, 
    Steven Lin, Patricia Garcia
    <br>
    <em>JAMA Network Open</em>, 2025
    <p></p>
    <p>
	Interviews with 22 physicians highlighted how ambient AI scribes may improve workload, workâ€“life integration, 
	and patient engagement, while revealing barriers and opportunities for adoption.
    </p>
  </td>
</tr>
		   <tr>
  <td style="padding:16px;width:20%;vertical-align:middle">
    <img src="images/interview.png" alt="Ambient AI Scribes article" width="160" style="border-radius:6px;">
  </td>

  <td style="padding:8px;width:80%;vertical-align:middle">
    <span class="papertitle"><a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2831866">Physician Perspectives on Ambient AI Scribes </a></span>
    <br>
    Shreya J Shah, Trevor Crowell, <strong>Yejin Jeong</strong>, Anna Devon-Sand, Margaret Smith, Betsy Yang, Stephen P Ma, 
    April S Liang, Clarissa Delahaie, Caroline Hsia, Tait Shanafelt, Michael A Pfeffer, Christopher Sharp, 
    Steven Lin, Patricia Garcia
    <br>
    <em>JAMA Network Open</em>, 2025
    <p></p>
    <p>
	Interviews with 22 physicians highlighted how ambient AI scribes may improve workload, workâ€“life integration, 
	and patient engagement, while revealing barriers and opportunities for adoption.
    </p>
  </td>
</tr>
		
			  
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Design and source code from <a href="https://jonbarron.info/">Jon Barron's website</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
